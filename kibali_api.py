#!/usr/bin/env python3
"""
API Flask pour connecter Kibali-IA avec Kibalone Studio
Expose les fonctions de Kibali comme endpoints API REST
Utilise LangChain pour orchestrer les outils IA
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import sys
import os
from pathlib import Path
import requests
import json

# Variables globales pour disponibilit√© des syst√®mes (D√âFINIR AU D√âBUT!)
DISPATCHER_AVAILABLE = False
ORCHESTRATOR_AVAILABLE = False
LANGCHAIN_AVAILABLE = False

# Ajouter le chemin de kibali-IA - CENTRALIS√â dans Isol
KIBALI_PATH = Path("/home/belikan/Isol/kibali-IA")
sys.path.insert(0, str(KIBALI_PATH))

# Imports de Kibali-IA
from dotenv import load_dotenv
load_dotenv(KIBALI_PATH / ".env")

# Import des configurations
sys.path.insert(0, str(KIBALI_PATH / "kibali_data" / "models"))
from MODEL_PATHS import *

# Imports des fonctionnalit√©s de Kibali
from huggingface_hub import InferenceClient
import torch

# LangChain pour orchestration des outils (OPTIONNEL - dispatcher est prioritaire)
try:
    from langchain.agents import Tool, AgentExecutor, create_react_agent
    from langchain.prompts import PromptTemplate
    from langchain_community.llms import HuggingFaceEndpoint
    LANGCHAIN_AVAILABLE = True
    
    # Import du registry complet des outils
    from kibali_tools_registry import get_all_tools, get_tools_summary, ALL_TOOLS_DEFINITIONS
    print("‚úÖ Kibali Tools Registry charg√©")
except ImportError:
    print("‚ö†Ô∏è LangChain non disponible - fonctionnement en mode simple")
    LANGCHAIN_AVAILABLE = False
    ALL_TOOLS_DEFINITIONS = []

# üöÄ DISPATCHER intelligent (BYPASS LANGCHAIN)
try:
    from kibali_dispatcher import KibaliDispatcher
    dispatcher = KibaliDispatcher()
    DISPATCHER_AVAILABLE = True
    print("‚úÖ Kibali Dispatcher charg√©")
except ImportError as e:
    print(f"‚ö†Ô∏è Dispatcher non disponible: {e}")
    DISPATCHER_AVAILABLE = False
    dispatcher = None

# üé≠ ORCHESTRATOR + EXECUTOR (Architecture finale!)
try:
    from kibali_orchestrator import orchestrate_prompt
    from kibali_executor import KibaliExecutor, process_prompt_full
    import asyncio
    print("‚úÖ Orchestrator + Executor charg√©s")
    ORCHESTRATOR_AVAILABLE = True
except ImportError as e:
    print(f"‚ö†Ô∏è Orchestrator non disponible: {e}")
    ORCHESTRATOR_AVAILABLE = False

app = Flask(__name__)
CORS(app)  # Permet les requ√™tes depuis le navigateur

# Variables globales
HF_TOKEN = os.getenv("HF_TOKEN")
inference_client = None
# Utilise un mod√®le RAPIDE pour l'interface temps r√©el
current_model = "mistralai/Mistral-7B-Instruct-v0.2"  # Plus rapide que Qwen-32B !

# Import du g√©n√©rateur 3D par CODE IA (nouvelle m√©thode !)
from ai_procedural_3d import generate_3d_by_ai, generate_animation_by_ai, generate_camera_by_ai, init_ai_generator

# üöÄ NOUVEAU: G√©n√©rateur HYBRIDE Mistral + CodeLlama
from hybrid_ai_generator import generate_hybrid_3d, init_hybrid_generator, fix_broken_code

# üñºÔ∏è NOUVEAU: Analyseur d'images (CLIP + OCR + YOLO)
from image_analyzer_api import init_analyzer

# Import du g√©n√©rateur AVANC√â avec multi-m√©thodes
from advanced_3d_generator import generate_advanced_3d

# Import du client TripoSR (isol√© avec framework isol)
from triposr_client_hf import TripoSRClientHF

# Initialise le g√©n√©rateur HYBRIDE au d√©marrage
print("üöÄ Initialisation du g√©n√©rateur HYBRIDE IA...")
print("   üß† Mistral: Raisonnement et analyse")
print("   üíª CodeLlama: G√©n√©ration de code complexe")
try:
    init_hybrid_generator()
    print("‚úÖ G√©n√©rateur Hybride pr√™t !")
except Exception as e:
    print(f"‚ö†Ô∏è G√©n√©rateur Hybride en mode d√©grad√©: {e}")

# Initialise le client TripoSR HF (d√©marrage lazy - au premier appel)
triposr_client = TripoSRClientHF()
triposr_initialized = False

# ============================================
# OUTILS LANGCHAIN - ORCHESTRATION IA
# ============================================

def tool_meshy_generate(prompt: str) -> str:
    """G√©n√®re un mod√®le 3D photor√©aliste avec Meshy.ai"""
    try:
        response = requests.post(
            'http://localhost:11003/api/text-to-3d-meshy',
            json={'prompt': prompt, 'art_style': 'realistic'},
            timeout=60
        )
        if response.ok:
            data = response.json()
            if data.get('success'):
                return f"‚úÖ Mod√®le 3D cr√©√©: {data.get('model_path', 'generated')}"
            return f"‚ö†Ô∏è {data.get('message', 'Erreur Meshy')}"
        return "‚ùå API Meshy non disponible"
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

def tool_midas_reconstruct(description: str) -> str:
    """Cr√©e une session de reconstruction 3D multi-vues avec MiDaS"""
    try:
        response = requests.post(
            'http://localhost:11002/api/create_session',
            json={'name': description, 'description': description},
            timeout=10
        )
        if response.ok:
            data = response.json()
            return f"‚úÖ Session reconstruction cr√©√©e: {data.get('session_id', 'N/A')}"
        return "‚ùå API MiDaS non disponible"
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

def tool_procedural_generate(prompt: str) -> str:
    """G√©n√®re un mod√®le 3D simple par code proc√©dural"""
    try:
        result = generate_3d_by_ai(prompt, 'character')
        if result.get('success'):
            return f"‚úÖ Code proc√©dural g√©n√©r√©: {len(result.get('code', ''))} caract√®res"
        return "‚ö†Ô∏è G√©n√©ration proc√©durale √©chou√©e"
    except Exception as e:
        return f"‚ùå Erreur: {str(e)}"

def tool_analyze_scene(query: str) -> str:
    """Analyse l'√©tat actuel de la sc√®ne 3D"""
    # TODO: Connecter √† un syst√®me de state management
    return "üìä Analyse de sc√®ne: 0 objets, cam√©ra √† (0,5,15)"

# D√©finition des outils LangChain
if LANGCHAIN_AVAILABLE:
    # Charge TOUS les outils depuis le registry
    tools = get_all_tools()
    print(f"‚úÖ {len(tools)} outils charg√©s depuis le registry")
    print(get_tools_summary())
    
    # Template pour l'agent ReAct
    react_template = """Tu es Kibali, un assistant IA expert en cr√©ation 3D pour Kibalone Studio.
Tu DOIS OBLIGATOIREMENT utiliser les outils disponibles pour TOUTES les demandes.

üéØ R√àGLES CRITIQUES:
1. Pour TOUTE demande d'objet/asset (colonne, terrain, b√¢timent, etc.) ‚Üí COMMENCE PAR FetchCompleteAsset
2. Si aucun asset trouv√© ‚Üí utilise Search3DModels OU SearchTextures
3. Si besoin d'info externe ‚Üí utilise WebSearch
4. Pour contr√¥le cam√©ra ‚Üí utilise les outils Camera*
5. NE R√âPONDS JAMAIS sans avoir essay√© au moins UN outil

EXEMPLES D'UTILISATION CORRECTE:
- "mets une colonne" ‚Üí Action: FetchCompleteAsset, Input: "colonne grecque"
- "cr√©e terrain football" ‚Üí Action: FetchCompleteAsset, Input: "terrain de football"  
- "cherche texture bois" ‚Üí Action: SearchTextures, Input: "wood"
- "cam√©ra tourne 360" ‚Üí Action: CameraOrbit360, Input: duration=8

Outils disponibles:
{tools}

Format de r√©ponse:
Question: la demande de l'utilisateur
Thought: ton raisonnement sur quelle(s) action(s) effectuer
Action: le nom de l'outil √† utiliser
Action Input: l'input pour l'outil
Observation: le r√©sultat de l'outil
... (r√©p√©ter Thought/Action/Action Input/Observation si n√©cessaire)
Thought: Je sais maintenant quoi r√©pondre
Final Answer: ta r√©ponse finale √† l'utilisateur

Question: {input}
{agent_scratchpad}"""

    print("‚úÖ Outils LangChain configur√©s")
    AGENT_EXECUTOR = None  # Sera initialis√© au premier appel
else:
    tools = []
    react_template = None
    AGENT_EXECUTOR = None

# ============================================
# INITIALISATION
# ============================================

def init_kibali():
    """Initialise le syst√®me Kibali"""
    global inference_client
    
    try:
        inference_client = InferenceClient(token=HF_TOKEN)
        print("‚úÖ Kibali-IA initialis√© avec succ√®s")
        return True
    except Exception as e:
        print(f"‚ùå Erreur init Kibali: {e}")
        return False

# ============================================
# ENDPOINTS API
# ============================================

@app.route('/api/health', methods=['GET'])
def health_check():
    """V√©rifie que l'API est active"""
    return jsonify({
        'status': 'ok',
        'service': 'Kibali-IA API',
        'version': '1.0',
        'model': current_model
    })

@app.route('/api/analyze-image', methods=['POST'])
def analyze_image():
    """
    Analyse une image de r√©f√©rence avec CLIP + OCR + YOLO
    
    Body: {
        "image": "data:image/png;base64,..." ou base64 direct,
        "context": "reference" (optionnel)
    }
    
    Returns: {
        "success": true,
        "analysis": {
            "description": "vehicle (confidence: 0.95)",
            "objects": [{class: "car", confidence: 0.89, bbox: [...]}],
            "text": [{text: "BMW", confidence: 0.92, bbox: [...]}],
            "colors": ["#ff0000", "#000000", "#ffffff"],
            "style": "realistic photo",
            "dimensions": {width: 800, height: 600}
        }
    }
    """
    try:
        data = request.json
        image_data = data.get('image', '')
        
        if not image_data:
            return jsonify({
                'success': False,
                'error': 'No image provided'
            }), 400
        
        print(f"üñºÔ∏è  Analyse d'image de r√©f√©rence...")
        
        # Initialise l'analyseur si n√©cessaire
        analyzer = init_analyzer()
        
        # Analyse l'image
        analysis = analyzer.analyze_image(image_data)
        
        print(f"‚úÖ Analyse termin√©e:")
        print(f"   Description: {analysis['description']}")
        print(f"   Objets d√©tect√©s: {len(analysis['objects'])}")
        print(f"   Texte trouv√©: {len(analysis['text'])}")
        print(f"   Couleurs: {analysis['colors']}")
        
        return jsonify({
            'success': True,
            'analysis': analysis
        })
        
    except Exception as e:
        print(f"‚ùå Erreur analyse image: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/chat', methods=['POST'])
def chat():
    """
    Endpoint principal pour le chat avec Kibali
    
    Body: {
        "message": "Cr√©e un personnage h√©ro√Øque",
        "context": "creation",
        "history": []
    }
    """
    try:
        data = request.json
        message = data.get('message', '')
        context = data.get('context', 'general')
        history = data.get('history', [])
        
        print(f"üì® [CHAT] Message re√ßu: {message[:50]}...")
        
        if not message:
            return jsonify({'error': 'Message vide'}), 400
        
        # Construction du prompt syst√®me selon le contexte
        print(f"üîß [CHAT] Context: {context}")
        system_prompt = get_system_prompt(context)
        
        # G√©n√©ration de la r√©ponse avec Kibali
        print(f"ü§ñ [CHAT] G√©n√©ration r√©ponse Kibali...")
        response = generate_response(message, system_prompt, history)
        print(f"‚úÖ [CHAT] R√©ponse g√©n√©r√©e: {len(response['text'])} chars")
        
        return jsonify({
            'success': True,
            'response': response['text'],
            'analysis': response.get('analysis', {}),
            'suggestions': response.get('suggestions', [])
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/generate-model', methods=['POST'])
def generate_model():
    """
    G√©n√®re un mod√®le 3D avec le g√©n√©rateur HYBRIDE IA
    üß† Mistral (raisonnement) + üíª CodeLlama (code complexe)
    
    Body: {
        "prompt": "un personnage h√©ro√Øque avec cape",
        "type": "character|object|environment"
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt', '')
        model_type = data.get('type', 'character')
        
        print(f"üöÄ [HYBRID-AI] G√©n√©ration: '{prompt}' (type: {model_type})")
        
        # Utilise le g√©n√©rateur HYBRIDE Mistral + CodeLlama
        result = generate_hybrid_3d(prompt, model_type)
        
        if result.get('success'):
            analysis = result.get('analysis', {})
            print(f"   ‚úÖ Analyse: {analysis.get('object_type')} / {analysis.get('style')}")
            print(f"   ‚úÖ Code: {len(result['code'])} caract√®res")
            
            return jsonify({
                'success': True,
                'model_data': {
                    'code': result['code'],
                    'type': 'javascript'
                },
                'analysis': analysis,
                'method_used': 'hybrid-mistral-codellama',
                'message': f"‚úÖ Code 3D g√©n√©r√© par Mistral + CodeLlama !"
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('error', 'Erreur g√©n√©ration'),
                'model_data': {'code': result.get('code', ''), 'type': 'javascript'}
            })
        
    except Exception as e:
        print(f"‚ùå Erreur generate-model: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'success': False, 'error': str(e)}), 500

@app.route('/api/fix-code', methods=['POST'])
def fix_code():
    """
    üîß AUTO-CORRECTION: Mistral corrige le code JavaScript cass√©
    
    Body: {
        "code": "le code probl√©matique",
        "error": "message d'erreur JavaScript",
        "prompt": "prompt original"
    }
    """
    try:
        data = request.json
        broken_code = data.get('code', '')
        error_msg = data.get('error', '')
        original_prompt = data.get('prompt', '')
        
        print(f"üîß [AUTO-FIX] Correction demand√©e: {error_msg[:50]}")
        
        # Demande √† Mistral de corriger
        result = fix_broken_code(broken_code, error_msg, original_prompt)
        
        if result.get('success'):
            print(f"   ‚úÖ Code corrig√©: {len(result['fixed_code'])} caract√®res")
            return jsonify(result)
        else:
            print(f"   ‚ùå Correction impossible")
            return jsonify(result), 400
        
    except Exception as e:
        print(f"‚ùå Erreur fix-code: {e}")
        return jsonify({'success': False, 'error': str(e)}), 500

    except Exception as e:
        print(f"‚ùå [HYBRID-AI] Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e), 'success': False}), 500

@app.route('/api/orchestrate', methods=['POST'])
def orchestrate():
    """
    üé≠ ENDPOINT ORCHESTR√â - Architecture finale!
    
    Kibali analyse le prompt et ORCHESTRE les 48 outils
    Retourne le plan + logs en temps r√©el
    
    Body: {
        "prompt": "cr√©e un personnage qui court et saute",
        "execute": true  // false = juste le plan, true = ex√©cution
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt', '')
        execute = data.get('execute', False)
        
        if not prompt:
            return jsonify({'error': 'Prompt vide'}), 400
        
        print(f"\n{'='*60}")
        print(f"üé≠ [ORCHESTRATE] Prompt: {prompt}")
        print(f"{'='*60}")
        
        if not ORCHESTRATOR_AVAILABLE:
            return jsonify({
                'success': False,
                'error': 'Orchestrator non disponible'
            }), 503
        
        # Phase 1: Orchestration (plan)
        orchestration = orchestrate_prompt(prompt)
        
        if not orchestration['understood']:
            return jsonify({
                'success': False,
                'error': 'Prompt non compris',
                'understood': False,
                'prompt': prompt
            })
        
        # Si mode "plan only", retourne juste le plan
        if not execute:
            return jsonify({
                'success': True,
                'understood': True,
                'plan': orchestration['plan'],
                'execution': None,
                'message': f"Plan cr√©√©: {len(orchestration['plan']['steps'])} √©tapes"
            })
        
        # Phase 2: Ex√©cution (appels API r√©els)
        try:
            # Execute en async
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(process_prompt_full(prompt))
            loop.close()
            
            return jsonify({
                'success': result['success'],
                'understood': True,
                'plan': result['orchestration']['plan'],
                'execution': result['execution'],
                'message': '‚úÖ Ex√©cution termin√©e' if result['success'] else '‚ö†Ô∏è Erreurs d√©tect√©es'
            })
        
        except Exception as e:
            print(f"‚ùå [ORCHESTRATE-EXEC] Erreur: {e}")
            return jsonify({
                'success': False,
                'understood': True,
                'plan': orchestration['plan'],
                'execution': None,
                'error': str(e)
            })
    
    except Exception as e:
        print(f"‚ùå [ORCHESTRATE] Erreur: {e}")
        return jsonify({'error': str(e), 'success': False}), 500

@app.route('/api/triposr-generate', methods=['POST'])
def triposr_generate():
    """
    G√©n√®re un mesh 3D depuis une image avec TripoSR (isol√©)
    
    Body: {
        "image_path": "/path/to/image.png",
        "output_path": "/path/to/output.obj" (optional),
        "resolution": 256 (optional)
    }
    """
    global triposr_initialized
    
    try:
        data = request.json
        image_path = data.get('image_path')
        output_path = data.get('output_path')
        resolution = data.get('resolution', 256)
        
        print(f"üé® [TripoSR] Demande g√©n√©ration depuis: {image_path}")
        
        if not image_path:
            return jsonify({'error': 'image_path requis'}), 400
        
        # Initialise TripoSR au premier appel
        if not triposr_initialized:
            print("üöÄ [TripoSR] Initialisation du service...")
            init_result = triposr_client.initialize()
            
            if not init_result.get('success'):
                return jsonify({
                    'error': f"√âchec initialisation TripoSR: {init_result.get('error')}"
                }), 500
            
            triposr_initialized = True
            print(f"‚úÖ [TripoSR] Service pr√™t sur {init_result.get('device')}")
        
        # G√©n√®re le mesh
        print(f"üîÑ [TripoSR] Conversion en cours (r√©solution: {resolution})...")
        result = triposr_client.image_to_3d(
            image_path=image_path,
            output_path=output_path,
            resolution=resolution
        )
        
        if result.get('success'):
            print(f"‚úÖ [TripoSR] Mesh g√©n√©r√©: {result.get('output_path')}")
            return jsonify({
                'success': True,
                'mesh_path': result.get('output_path'),
                'vertices': result.get('vertices'),
                'faces': result.get('faces')
            })
        else:
            return jsonify({
                'error': f"G√©n√©ration √©chou√©e: {result.get('error')}"
            }), 500
    
    except Exception as e:
        print(f"‚ùå [TripoSR] Erreur: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/text-to-3d', methods=['POST'])
def text_to_3d():
    """
    G√©n√®re un mesh 3D depuis un prompt texte avec PLUSIEURS M√âTHODES:
    - 'advanced': Code IA avec anatomie d√©taill√©e
    - 'grease-pencil': Dessin 2D dans 3D
    - 'blender-style': Mod√©lisation avanc√©e
    - 'auto': D√©tection automatique
    
    Body: {
        "prompt": "un guerrier avec √©p√©e",
        "method": "advanced" (optionnel: advanced, grease-pencil, blender-style, auto)
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt')
        method = data.get('method', 'auto')
        
        print(f"üé® [3D Avanc√©] Prompt: {prompt}, M√©thode: {method}")
        
        if not prompt:
            return jsonify({'error': 'prompt requis'}), 400
        
        # G√©n√®re avec le nouveau syst√®me
        result = generate_advanced_3d(prompt, method)
        
        if result.get('success'):
            print(f"‚úÖ [3D Avanc√©] G√©n√©r√© avec m√©thode: {result['method']}")
            return jsonify({
                'success': True,
                'code': result['code'],
                'method': result['method'],
                'type': 'javascript'
            })
        else:
            return jsonify({
                'error': f"G√©n√©ration √©chou√©e: {result.get('error')}"
            }), 500
    
    except Exception as e:
        print(f"‚ùå [3D Avanc√©] Erreur: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/launch-demo', methods=['POST'])
def launch_demo():
    """
    üé¨ Lance la d√©mo MiDaS avec les photos du Ch√¢teau de Sceaux
    Reconstruit le mesh 3D et le charge dans la sc√®ne
    
    Body: {
        "num_photos": 3 (optionnel, d√©faut=3, max=11)
    }
    """
    try:
        data = request.json or {}
        num_photos = min(int(data.get('num_photos', 11)), 11)  # Utilise 11 photos par d√©faut
        
        print(f"üé¨ [D√âMO] Lancement reconstruction ch√¢teau ({num_photos} photos)")
        
        # Import du client MiDaS
        import sys
        from pathlib import Path
        sys.path.insert(0, '/home/belikan/Isol/isol-framework')
        from midas_client import MiDaSClient
        
        # Photos du ch√¢teau
        photos_dir = Path("/home/belikan/Isol/Kibalone-Studio/static/assets/test_images")
        photos = sorted(photos_dir.glob("image_*.jpg"))[:num_photos]
        
        if not photos:
            return jsonify({
                'success': False,
                'error': 'Aucune photo trouv√©e'
            }), 404
        
        print(f"   üì∏ {len(photos)} photos s√©lectionn√©es")
        
        # Client MiDaS
        client = MiDaSClient()
        
        # Init
        print("   ‚öôÔ∏è  Init MiDaS...")
        init_result = client.initialize()
        if not init_result.get('success'):
            return jsonify({
                'success': False,
                'error': 'MiDaS init failed'
            }), 500
        
        # Reconstruction
        output_path = "/home/belikan/Isol/Kibalone-Studio/outputs/chateau_demo.obj"
        print(f"   üîÆ Reconstruction ‚Üí {output_path}")
        
        result = client.reconstruct_batch(
            image_paths=[str(p) for p in photos],
            preset="photogrammetry",
            output_path=output_path
        )
        
        if not result.get('success'):
            return jsonify({
                'success': False,
                'error': result.get('error', 'Reconstruction failed')
            }), 500
        
        mesh_path = result.get('output_path', output_path)
        vertices = result.get('vertices', 0)
        triangles = result.get('triangles', 0)
        
        print(f"   ‚úÖ Mesh: {vertices} vertices, {triangles} triangles")
        
        # Convertit le chemin absolu en chemin relatif pour le frontend
        # /home/belikan/Isol/Kibalone-Studio/outputs/chateau_demo.obj ‚Üí /outputs/chateau_demo.obj
        relative_mesh_path = mesh_path.replace('/home/belikan/Isol/Kibalone-Studio', '')
        
        # G√©n√®re code Three.js pour charger le mesh
        threejs_code = f"""
// Ch√¢teau de Sceaux - Reconstruction MiDaS ({num_photos} photos)
(function() {{
    const loader = new THREE.OBJLoader();
    addLog('üì¶ Chargement du mesh...');
    console.log('üîç Tentative chargement:', '{relative_mesh_path}');
    
    loader.load(
        '{relative_mesh_path}',
        (obj) => {{
            console.log('‚úÖ OBJ charg√©:', obj);
            addLog('‚úÖ Mesh charg√© avec succ√®s');
            
            // Centre et scale
            const box = new THREE.Box3().setFromObject(obj);
            const center = box.getCenter(new THREE.Vector3());
            const size = box.getSize(new THREE.Vector3());
            const maxDim = Math.max(size.x, size.y, size.z);
            const scale = 5 / maxDim;
            
            obj.position.sub(center);
            obj.scale.set(scale, scale, scale);
            
            // Mat√©riau pierre
            obj.traverse((child) => {{
                if (child.isMesh) {{
                    child.material = new THREE.MeshStandardMaterial({{
                        color: 0xC8A882,
                        roughness: 0.8,
                        metalness: 0.1
                    }});
                    child.castShadow = true;
                    child.receiveShadow = true;
                }}
            }});
            
            studio.scene.add(obj);
            addLog('‚úÖ Ch√¢teau affich√© dans la sc√®ne!');
            addLog('üìä {vertices} vertices, {triangles} triangles');
        }},
        (xhr) => {{
            if (xhr.lengthComputable) {{
                const percent = Math.round((xhr.loaded / xhr.total) * 100);
                if (percent % 25 === 0) {{
                    console.log(`Chargement: ${{percent}}%`);
                    addLog(`‚è≥ Chargement: ${{percent}}%`);
                }}
            }}
        }},
        (error) => {{
            console.error('‚ùå Erreur OBJLoader:', error);
            console.error('Path tent√©:', '{relative_mesh_path}');
            addLog('‚ùå Erreur chargement mesh');
            addLog('URL: {relative_mesh_path}');
        }}
    );
}})();
"""
        
        return jsonify({
            'success': True,
            'code': threejs_code,
            'type': 'javascript',
            'mesh_path': mesh_path,
            'stats': {
                'photos': len(photos),
                'vertices': vertices,
                'triangles': triangles
            },
            'message': f'üè∞ Ch√¢teau reconstruit depuis {len(photos)} photos!'
        })
        
    except Exception as e:
        print(f"‚ùå [D√âMO] Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/upload-reconstruct', methods=['POST'])
def upload_reconstruct():
    """
    üì§ Upload photos et lance reconstruction MiDaS
    Sauvegarde dans /outputs/ et retourne le chemin du mesh
    
    FormData: files[] - Liste de fichiers image
    """
    try:
        if 'photos' not in request.files:
            return jsonify({
                'success': False,
                'error': 'Aucune photo upload√©e'
            }), 400
        
        files = request.files.getlist('photos')
        if len(files) == 0:
            return jsonify({
                'success': False,
                'error': 'Liste de photos vide'
            }), 400
        
        print(f"üì§ [UPLOAD] {len(files)} photos re√ßues")
        
        # Cr√©e un dossier temporaire pour les uploads
        import tempfile
        import shutil
        from datetime import datetime
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        temp_dir = Path(tempfile.mkdtemp(prefix=f"upload_{timestamp}_"))
        
        # Sauvegarde les fichiers upload√©s
        photo_paths = []
        for i, file in enumerate(files):
            if file.filename:
                ext = Path(file.filename).suffix
                photo_path = temp_dir / f"photo_{i:03d}{ext}"
                file.save(str(photo_path))
                photo_paths.append(photo_path)
                print(f"   üìÅ Sauvegard√©: {photo_path.name}")
        
        if len(photo_paths) == 0:
            shutil.rmtree(temp_dir)
            return jsonify({
                'success': False,
                'error': 'Aucune photo valide'
            }), 400
        
        # Import du client MiDaS
        import sys
        sys.path.insert(0, '/home/belikan/Isol/isol-framework')
        from midas_client import MiDaSClient
        
        # Client MiDaS
        client = MiDaSClient()
        
        # Init
        print("   ‚öôÔ∏è  Init MiDaS...")
        init_result = client.initialize()
        if not init_result.get('success'):
            shutil.rmtree(temp_dir)
            return jsonify({
                'success': False,
                'error': 'MiDaS init failed'
            }), 500
        
        # Reconstruction
        output_filename = f"reconstruction_{timestamp}.obj"
        output_path = f"/home/belikan/Isol/Kibalone-Studio/outputs/{output_filename}"
        print(f"   üîÆ Reconstruction ‚Üí {output_path}")
        
        result = client.reconstruct_batch(
            image_paths=[str(p) for p in photo_paths],
            preset="photogrammetry",
            output_path=output_path
        )
        
        # Nettoyage du dossier temporaire
        shutil.rmtree(temp_dir)
        
        if not result.get('success'):
            return jsonify({
                'success': False,
                'error': result.get('error', 'Reconstruction failed')
            }), 500
        
        mesh_path = result.get('output_path', output_path)
        vertices = result.get('vertices', 0)
        triangles = result.get('triangles', 0)
        
        print(f"   ‚úÖ Mesh: {vertices} vertices, {triangles} triangles")
        print(f"   üíæ Sauvegard√©: {output_filename}")
        
        # Chemin relatif pour le frontend
        relative_mesh_path = f"/outputs/{output_filename}"
        
        # G√©n√®re code Three.js pour charger le mesh
        threejs_code = f"""
(function() {{
    const loader = new THREE.OBJLoader();
    addLog('üì¶ Chargement du mesh reconstruit...');
    
    loader.load(
        '{relative_mesh_path}',
        (obj) => {{
            const box = new THREE.Box3().setFromObject(obj);
            const center = box.getCenter(new THREE.Vector3());
            const size = box.getSize(new THREE.Vector3());
            const maxDim = Math.max(size.x, size.y, size.z);
            const scale = 5 / maxDim;
            
            obj.position.sub(center);
            obj.scale.set(scale, scale, scale);
            
            obj.traverse((child) => {{
                if (child.isMesh) {{
                    child.material = new THREE.MeshStandardMaterial({{
                        color: 0x888888,
                        roughness: 0.7,
                        metalness: 0.2
                    }});
                    child.castShadow = true;
                    child.receiveShadow = true;
                }}
            }});
            
            studio.scene.add(obj);
            addLog('‚úÖ Reconstruction affich√©e!');
            addLog('üìä {vertices} vertices, {triangles} triangles');
            addLog('üíæ Sauvegard√©: {output_filename}');
        }},
        (xhr) => {{
            if (xhr.lengthComputable) {{
                const percent = Math.round((xhr.loaded / xhr.total) * 100);
                if (percent % 25 === 0) {{
                    addLog(`‚è≥ Chargement: ${{percent}}%`);
                }}
            }}
        }},
        (error) => {{
            addLog('‚ùå Erreur chargement mesh');
            console.error('Erreur:', error);
        }}
    );
}})();
"""
        
        return jsonify({
            'success': True,
            'code': threejs_code,
            'type': 'javascript',
            'mesh_path': mesh_path,
            'relative_path': relative_mesh_path,
            'filename': output_filename,
            'stats': {
                'photos': len(photo_paths),
                'vertices': vertices,
                'triangles': triangles
            },
            'message': f'‚úÖ Reconstruction depuis {len(photo_paths)} photos!'
        })
        
    except Exception as e:
        print(f"‚ùå [UPLOAD] Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/api/grease-pencil', methods=['POST'])
def grease_pencil():
    """
    Dessine en 2D dans l'espace 3D (style Grease Pencil Blender)
    
    Body: {
        "prompt": "dessine un dragon qui vole",
        "style": "sketch" (optionnel)
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt')
        
        print(f"‚úèÔ∏è [Grease Pencil] Prompt: {prompt}")
        
        if not prompt:
            return jsonify({'error': 'prompt requis'}), 400
        
        # Force la m√©thode grease-pencil
        result = generate_advanced_3d(prompt, 'grease-pencil')
        
        if result.get('success'):
            print(f"‚úÖ [Grease Pencil] Dessin g√©n√©r√©")
            return jsonify({
                'success': True,
                'code': result['code'],
                'method': 'grease-pencil',
                'type': 'javascript'
            })
        else:
            return jsonify({
                'error': f"G√©n√©ration √©chou√©e: {result.get('error')}"
            }), 500
    
    except Exception as e:
        print(f"‚ùå [Grease Pencil] Erreur: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/api/analyze-prompt', methods=['POST'])
def analyze_prompt():
    """
    Analyse un prompt pour comprendre l'intention ET ORCHESTRER LES OUTILS
    üöÄ UTILISE LE DISPATCHER INTELLIGENT (bypass LangChain)
    
    Body: {
        "prompt": "anime le personnage en marchant",
        "context": "animation",
        "use_dispatcher": true  # Active le dispatcher (par d√©faut)
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt', '')
        context = data.get('context', 'general')
        use_dispatcher = data.get('use_dispatcher', True)  # Dispatcher par d√©faut
        
        import sys
        sys.stderr.write(f"üß† [ANALYZE] Prompt: '{prompt}'\n")
        sys.stderr.write(f"üîß [ANALYZE] use_dispatcher={use_dispatcher}, DISPATCHER_AVAILABLE={DISPATCHER_AVAILABLE}\n")
        sys.stderr.flush()
        
        # üöÄ MODE DISPATCHER - Pattern matching intelligent (PRIORITAIRE)
        if use_dispatcher and DISPATCHER_AVAILABLE:
            sys.stderr.write(f"‚ö° [ANALYZE] Mode DISPATCHER activ√©!\n")
            sys.stderr.flush()
            
            # Utilise dispatch_and_execute qui fait: analyze + execute
            from kibali_dispatcher import dispatch_and_execute
            result = dispatch_and_execute(prompt)
            
            sys.stderr.write(f"‚úÖ [ANALYZE] Dispatcher result: {result}\n")
            sys.stderr.flush()
            
            return jsonify(result)
        
        # MODE AGENT LANGCHAIN - Fallback si dispatcher indisponible
        elif LANGCHAIN_AVAILABLE:
            sys.stderr.write(f"üöÄ [ANALYZE] Mode AGENT LangChain (fallback)\n")
            sys.stderr.flush()
            result = execute_agent_task(prompt)
            sys.stderr.write(f"‚úÖ [ANALYZE] Agent result: {result}\n")
            sys.stderr.flush()
            return jsonify(result)
        
        # MODE SIMPLE - Analyse basique sans outils
        else:
            sys.stderr.write(f"‚ö†Ô∏è [ANALYZE] Mode SIMPLE (ni dispatcher ni agent)\n")
            sys.stderr.flush()
            analysis = analyze_with_kibali(prompt, context)
            
            return jsonify({
                'success': True,
                'intent': analysis['intent'],
                'parameters': analysis['parameters'],
                'suggestions': analysis['suggestions']
            })
        
    except Exception as e:
        print(f"‚ùå [ANALYZE] Erreur: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({'error': str(e)}), 500

def execute_agent_task(prompt: str) -> dict:
    """Ex√©cute une t√¢che avec l'agent LangChain"""
    global AGENT_EXECUTOR
    
    try:
        # Initialise l'agent si n√©cessaire
        if AGENT_EXECUTOR is None and LANGCHAIN_AVAILABLE:
            print("ü§ñ Initialisation de l'agent LangChain...")
            
            # Cr√©e un LLM HuggingFace
            llm = HuggingFaceEndpoint(
                endpoint_url=f"https://api-inference.huggingface.co/models/{current_model}",
                huggingfacehub_api_token=HF_TOKEN,
                temperature=0.7,
                max_new_tokens=512
            )
            
            # Cr√©e le prompt template
            prompt_template = PromptTemplate(
                template=react_template,
                input_variables=["input", "agent_scratchpad"],
                partial_variables={"tools": "\n".join([f"{t.name}: {t.description}" for t in tools])}
            )
            
            # Cr√©e l'agent
            agent = create_react_agent(llm, tools, prompt_template)
            AGENT_EXECUTOR = AgentExecutor(
                agent=agent,
                tools=tools,
                verbose=True,
                max_iterations=5,
                handle_parsing_errors=True
            )
            print("‚úÖ Agent LangChain pr√™t")
        
        # Ex√©cute l'agent
        if AGENT_EXECUTOR:
            print(f"üöÄ Ex√©cution agent pour: '{prompt}'")
            result = AGENT_EXECUTOR.invoke({"input": prompt})
            
            # Parse le r√©sultat
            output = result.get('output', '')
            
            # Extrait les infos de l'ex√©cution
            tools_used = []
            for tool in tools:
                if tool.name in str(result):
                    tools_used.append(tool.name)
            
            return {
                'success': True,
                'intent': 'create',  # TODO: extraire du r√©sultat
                'parameters': {
                    'type': 'character',  # TODO: extraire
                    'description': prompt,
                    'tool': tools_used[0] if tools_used else 'procedural',
                    'tools_used': tools_used
                },
                'agent_output': output,
                'suggestions': [output]
            }
        else:
            raise Exception("Agent non disponible")
            
    except Exception as e:
        import sys, traceback
        sys.stderr.write(f"‚ùå Agent erreur: {e}\n")
        sys.stderr.write(f"üìã Traceback:\n{traceback.format_exc()}\n")
        sys.stderr.flush()
        # Fallback sur analyse simple
        return analyze_with_kibali(prompt, 'general')

@app.route('/api/agent-execute', methods=['POST'])
def agent_execute():
    """
    Endpoint d√©di√© pour ex√©cuter l'agent avec tous les outils
    
    Body: {
        "task": "Cr√©e un personnage h√©ro√Øque et ajoute une lumi√®re dramatique",
        "max_iterations": 5
    }
    """
    try:
        data = request.json
        task = data.get('task', '')
        max_iter = data.get('max_iterations', 5)
        
        if not LANGCHAIN_AVAILABLE:
            return jsonify({
                'error': 'LangChain non disponible. Installez: pip install langchain langchain-community'
            }), 503
        
        print(f"ü§ñ [AGENT] T√¢che: {task}")
        result = execute_agent_task(task)
        
        return jsonify(result)
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/generate-animation', methods=['POST'])
def generate_animation():
    """
    G√©n√®re des keyframes d'animation
    
    Body: {
        "prompt": "marche vers l'avant pendant 3 secondes",
        "object_type": "character",
        "duration_frames": 90
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt', '')
        object_type = data.get('object_type', 'character')
        duration = data.get('duration_frames', 90)
        
        # G√©n√®re les keyframes avec Kibali
        keyframes = generate_animation_keyframes(prompt, object_type, duration)
        
        return jsonify({
            'success': True,
            'keyframes': keyframes,
            'duration': duration,
            'fps': 30
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-control', methods=['POST'])
def camera_control():
    """
    Contr√¥le de la cam√©ra par prompt
    
    Body: {
        "prompt": "cam√©ra orbite autour du personnage",
        "current_position": {x, y, z}
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt', '')
        current_pos = data.get('current_position', {'x': 5, 'y': 5, 'z': 5})
        
        # Analyse et g√©n√®re le mouvement de cam√©ra
        camera_path = generate_camera_movement(prompt, current_pos)
        
        return jsonify({
            'success': True,
            'camera_path': camera_path,
            'animation_type': camera_path['type']
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/axis-widget', methods=['POST'])
def toggle_axis_widget():
    """Toggle le widget d'orientation des axes"""
    try:
        data = request.json or {}
        action = data.get('action', 'toggle')
        return jsonify({
            'success': True,
            'action': action,
            'message': f'Widget d\'axes {action}',
            'widget_visible': action in ['toggle', 'show']
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ============================================
# ENDPOINTS CAM√âRA EXPERT - 10 CONTR√îLES
# ============================================

@app.route('/api/camera-orbit', methods=['POST'])
def camera_orbit():
    """Orbite 360¬∞ autour de la sc√®ne"""
    try:
        data = request.json or {}
        duration = data.get('duration', 8000)
        height = data.get('height', 5)
        radius = data.get('radius', 8)
        return jsonify({
            'success': True,
            'command': 'orbit360',
            'params': {'duration': duration, 'height': height, 'radius': radius}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-move', methods=['POST'])
def camera_move_endpoint():
    """D√©place la cam√©ra dans une direction"""
    try:
        data = request.json or {}
        direction = data.get('direction', 'forward')
        distance = data.get('distance', 2)
        duration = data.get('duration', 1000)
        return jsonify({
            'success': True,
            'command': 'move',
            'params': {'direction': direction, 'distance': distance, 'duration': duration}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-rotate', methods=['POST'])
def camera_rotate_endpoint():
    """Rotation sur un axe"""
    try:
        data = request.json or {}
        axis = data.get('axis', 'y')
        degrees = data.get('degrees', 90)
        duration = data.get('duration', 1000)
        return jsonify({
            'success': True,
            'command': 'rotate',
            'params': {'axis': axis, 'degrees': degrees, 'duration': duration}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-flyto', methods=['POST'])
def camera_flyto():
    """Vol cin√©matique vers position"""
    try:
        data = request.json or {}
        x = data.get('x', 0)
        y = data.get('y', 10)
        z = data.get('z', 5)
        duration = data.get('duration', 2000)
        return jsonify({
            'success': True,
            'command': 'flyto',
            'params': {'x': x, 'y': y, 'z': z, 'duration': duration}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-lookat', methods=['POST'])
def camera_lookat():
    """Change le point de focus"""
    try:
        data = request.json or {}
        x = data.get('x', 0)
        y = data.get('y', 0)
        z = data.get('z', 0)
        return jsonify({
            'success': True,
            'command': 'lookat',
            'params': {'x': x, 'y': y, 'z': z}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-zoom', methods=['POST'])
def camera_zoom_endpoint():
    """Zoom in/out"""
    try:
        data = request.json or {}
        factor = data.get('factor', 1.5)
        duration = data.get('duration', 500)
        return jsonify({
            'success': True,
            'command': 'zoom',
            'params': {'factor': factor, 'duration': duration}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-pan', methods=['POST'])
def camera_pan_endpoint():
    """Pan horizontal/vertical"""
    try:
        data = request.json or {}
        horizontal = data.get('horizontal', 0)
        vertical = data.get('vertical', 0)
        duration = data.get('duration', 1000)
        return jsonify({
            'success': True,
            'command': 'pan',
            'params': {'horizontal': horizontal, 'vertical': vertical, 'duration': duration}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-shake', methods=['POST'])
def camera_shake_endpoint():
    """Effet shake (explosion, impact)"""
    try:
        data = request.json or {}
        intensity = data.get('intensity', 0.3)
        duration = data.get('duration', 500)
        return jsonify({
            'success': True,
            'command': 'shake',
            'params': {'intensity': intensity, 'duration': duration}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-preset', methods=['POST'])
def camera_preset_endpoint():
    """Positions pr√©r√©gl√©es"""
    try:
        data = request.json or {}
        preset = data.get('preset', 'iso')
        return jsonify({
            'success': True,
            'command': 'preset',
            'params': {'preset': preset}
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/api/camera-stop', methods=['POST'])
def camera_stop_endpoint():
    """Arr√™te toute animation de cam√©ra"""
    try:
        return jsonify({
            'success': True,
            'command': 'stop'
        })
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# ============================================
# FONCTIONS INTERNES
# ============================================

def get_system_prompt(context):
    """Retourne le prompt syst√®me selon le contexte"""
    prompts = {
        'creation': """Tu es Kibali, assistant expert en cr√©ation 3D pour Kibalone Studio.
IMPORTANT: R√©ponds UNIQUEMENT en fran√ßais, de mani√®re COURTE (maximum 2-3 phrases).
Tu aides √† cr√©er des mod√®les 3D (personnages, objets, environnements).
Confirme rapidement ce que tu vas cr√©er, sans d√©tails techniques.
Exemple: "Je cr√©e un guerrier h√©ro√Øque avec armure et √©p√©e !"
""",
        
        'animation': """Tu es Kibali, expert en animation 3D.
IMPORTANT: R√©ponds UNIQUEMENT en fran√ßais, de mani√®re COURTE (1-2 phrases).
Confirme l'animation que tu vas cr√©er.
Exemple: "J'anime le personnage en marche !"
""",
        
        'camera': """Tu es Kibali, directeur photo virtuel.
IMPORTANT: R√©ponds UNIQUEMENT en fran√ßais, de mani√®re COURTE (1-2 phrases).
Confirme le mouvement de cam√©ra.
Exemple: "Cam√©ra en orbite autour de la sc√®ne !"
""",
        
        'general': """Tu es Kibali, assistant IA pour la cr√©ation 3D dans Kibalone Studio.
IMPORTANT: 
- R√©ponds UNIQUEMENT en fran√ßais
- Sois TR√àS BREF (maximum 2-3 phrases)
- Confirme rapidement sans explications longues
Tu comprends les demandes de cr√©ation 3D et r√©ponds de fa√ßon concise."""
    }
    
    return prompts.get(context, prompts['general'])

def generate_response(message, system_prompt, history):
    """G√©n√®re une r√©ponse avec Kibali - VERSION RAPIDE ET COURTE"""
    global inference_client, current_model
    
    print(f"ü§ñ [KIBALI] D√©but g√©n√©ration... (mod√®le: {current_model})")
    
    # Construction des messages avec instruction de bri√®vet√©
    messages = [{"role": "system", "content": system_prompt + "\n\nRAPPEL: R√©ponds en fran√ßais, maximum 2-3 phrases courtes."}]
    
    # Ajoute l'historique (R√âDUIT pour vitesse)
    for msg in history[-2:]:  # Seulement 2 derniers messages au lieu de 5
        messages.append(msg)
    
    messages.append({"role": "user", "content": message})
    
    # G√©n√©ration
    response_text = ""
    try:
        stream = inference_client.chat.completions.create(
            model=current_model,
            messages=messages,
            max_tokens=200,  # R√âDUIT √† 200 pour r√©ponses courtes
            temperature=0.7,
            stream=True
        )
        
        for chunk in stream:
            if chunk.choices[0].delta.content:
                response_text += chunk.choices[0].delta.content
        
        print(f"‚úÖ [KIBALI] R√©ponse g√©n√©r√©e: {len(response_text)} chars")
        
        return {
            'text': response_text,
            'analysis': parse_analysis(response_text),
            'suggestions': []
        }
        
    except Exception as e:
        return {
            'text': f"Erreur: {str(e)}",
            'analysis': {},
            'suggestions': []
        }

def analyze_with_kibali(prompt, context):
    """Analyse un prompt avec Kibali"""
    system_prompt = f"""Analyse ce prompt pour la cr√©ation 3D.
Retourne un JSON avec:
- intent: l'intention (create, animate, camera, light, etc.)
- parameters: {{
    type: le type d'objet (character, environment, object, etc.),
    description: description extraite,
    complexity: niveau de complexit√© (1-10),
    tool: l'outil √† utiliser (meshy, triposr, midas, procedural)
  }}
- suggestions: des suggestions d'am√©lioration

Prompt: {prompt}
Context: {context}

Choix de l'outil:
- meshy: pour g√©n√©ration 3D r√©aliste et d√©taill√©e (n√©cessite API key)
- triposr: pour conversion image‚Üí3D (actuellement non disponible)
- midas: pour reconstruction 3D multi-vues/photogramm√©trie
- procedural: g√©n√©ration proc√©durale simple (fallback)"""
    
    response = generate_response(prompt, system_prompt, [])
    
    try:
        # Parse le JSON de la r√©ponse
        json_start = response['text'].find('{')
        json_end = response['text'].rfind('}') + 1
        if json_start != -1 and json_end > json_start:
            result = json.loads(response['text'][json_start:json_end])
            # Assure qu'il y a un tool par d√©faut
            if 'parameters' in result and 'tool' not in result['parameters']:
                result['parameters']['tool'] = 'procedural'
            return result
    except:
        pass
    
    # Fallback simple
    intent = detect_intent(prompt)
    obj_type = 'character' if 'character' in intent or 'personnage' in prompt.lower() else \
               'environment' if 'environment' in intent or 'environnement' in prompt.lower() else \
               'object'
    
    return {
        'intent': intent,
        'parameters': {
            'type': obj_type,
            'description': prompt,
            'complexity': 5,
            'tool': 'procedural'  # Par d√©faut
        },
        'suggestions': []
    }

def detect_intent(prompt):
    """D√©tecte l'intention basique du prompt"""
    prompt_lower = prompt.lower()
    
    if any(word in prompt_lower for word in ['cr√©e', 'cr√©er', 'g√©n√®re', 'ajoute']):
        if 'personnage' in prompt_lower or 'character' in prompt_lower:
            return 'create_character'
        elif 'environnement' in prompt_lower or 'environment' in prompt_lower:
            return 'create_environment'
        elif 'objet' in prompt_lower or 'object' in prompt_lower:
            return 'create_object'
        return 'create'
    
    elif any(word in prompt_lower for word in ['anime', 'animer', 'mouvement', 'bouge']):
        return 'animate'
    
    elif any(word in prompt_lower for word in ['cam√©ra', 'camera', 'vue', 'plan']):
        return 'camera'
    
    elif any(word in prompt_lower for word in ['lumi√®re', 'light', '√©clairage']):
        return 'light'
    
    return 'general'

def analyze_model_prompt(prompt, model_type):
    """Analyse un prompt de cr√©ation de mod√®le"""
    system_prompt = f"""Analyse ce prompt pour cr√©er un mod√®le 3D de type {model_type}.
Extrais:
- forme de base (humanoid, spherical, cubic, etc.)
- caract√©ristiques (taille, couleur, style)
- complexit√© (1-10)
- est_organique (true/false)

Prompt: {prompt}"""
    
    response = generate_response(prompt, system_prompt, [])
    
    return {
        'prompt': prompt,
        'type': model_type,
        'shape': 'humanoid' if 'personnage' in prompt.lower() else 'cubic',
        'scale': 1.0,
        'complexity': 5,
        'organic': model_type == 'character'
    }

def generate_procedural_model(analysis):
    """G√©n√®re un mod√®le proc√©dural simple"""
    # Retourne les donn√©es pour g√©n√©rer c√¥t√© client
    return {
        'type': 'procedural',
        'shape': analysis['shape'],
        'scale': analysis['scale'],
        'vertices': [],  # √Ä g√©n√©rer c√¥t√© client
        'faces': [],
        'ready': True
    }

def generate_ai_model(analysis):
    """G√©n√®re un mod√®le avec IA (placeholder)"""
    return {
        'type': 'ai_generated',
        'status': 'processing',
        'message': 'G√©n√©ration IA en cours...',
        'ready': False
    }

def generate_animation_keyframes(prompt, object_type, duration):
    """G√©n√®re des keyframes d'animation"""
    # Analyse le prompt
    if 'marche' in prompt.lower() or 'walk' in prompt.lower():
        # Animation de marche
        keyframes = []
        for frame in range(0, duration, 15):
            keyframes.append({
                'frame': frame,
                'transformation': {
                    'translation': {'x': 0, 'y': 0, 'z': frame * 0.05},
                    'rotation': {'x': 0, 'y': 0, 'z': 0},
                    'scale': {'x': 1, 'y': 1, 'z': 1}
                }
            })
        return keyframes
    
    elif 'rotation' in prompt.lower() or 'tourne' in prompt.lower():
        # Animation de rotation
        keyframes = []
        for frame in range(0, duration, 10):
            angle = (frame / duration) * 360
            keyframes.append({
                'frame': frame,
                'transformation': {
                    'translation': {'x': 0, 'y': 0, 'z': 0},
                    'rotation': {'x': 0, 'y': angle, 'z': 0},
                    'scale': {'x': 1, 'y': 1, 'z': 1}
                }
            })
        return keyframes
    
    # Default: simple keyframes
    return [
        {'frame': 0, 'transformation': {'translation': {'x': 0, 'y': 0, 'z': 0}, 'rotation': {'x': 0, 'y': 0, 'z': 0}, 'scale': {'x': 1, 'y': 1, 'z': 1}}},
        {'frame': duration, 'transformation': {'translation': {'x': 0, 'y': 0, 'z': 0}, 'rotation': {'x': 0, 'y': 0, 'z': 0}, 'scale': {'x': 1, 'y': 1, 'z': 1}}}
    ]

def generate_camera_movement(prompt, current_pos):
    """G√©n√®re un mouvement de cam√©ra"""
    if 'orbite' in prompt.lower() or 'orbit' in prompt.lower():
        return {
            'type': 'orbit',
            'center': {'x': 0, 'y': 0, 'z': 0},
            'radius': 10,
            'duration': 120,
            'start_angle': 0,
            'end_angle': 360
        }
    
    elif 'zoom' in prompt.lower():
        return {
            'type': 'zoom',
            'start': current_pos,
            'end': {'x': current_pos['x'] * 0.5, 'y': current_pos['y'] * 0.5, 'z': current_pos['z'] * 0.5},
            'duration': 60
        }
    
    else:
        return {
            'type': 'static',
            'position': current_pos
        }

def parse_analysis(text):
    """Parse l'analyse depuis le texte de r√©ponse"""
    # Cherche du JSON dans la r√©ponse
    try:
        json_start = text.find('{')
        json_end = text.rfind('}') + 1
        if json_start != -1 and json_end > json_start:
            return json.loads(text[json_start:json_end])
    except:
        pass

# üß™ ENDPOINT DE DEBUG POUR TESTER LE DISPATCHER
@app.route('/api/dispatcher/test', methods=['POST'])
def test_dispatcher():
    """
    Test le dispatcher avec un prompt
    Retourne le matching de pattern sans ex√©cuter
    
    Body: {
        "prompt": "fait moi un terrain de foot"
    }
    """
    try:
        data = request.json
        prompt = data.get('prompt', '')
        
        if not DISPATCHER_AVAILABLE:
            return jsonify({
                'error': 'Dispatcher non disponible',
                'dispatcher_available': False
            }), 503
        
        # Analyse le prompt
        plan = dispatcher.analyze(prompt)
        
        return jsonify({
            'success': True,
            'prompt': prompt,
            'plan': plan,
            'dispatcher_available': True
        })
        
    except Exception as e:
        import traceback
        return jsonify({
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500

@app.route('/api/dispatcher/patterns', methods=['GET'])
def get_dispatcher_patterns():
    """
    Retourne tous les patterns disponibles dans le dispatcher
    Utile pour la documentation
    """
    try:
        if not DISPATCHER_AVAILABLE:
            return jsonify({
                'error': 'Dispatcher non disponible',
                'dispatcher_available': False
            }), 503
        
        # Compte les patterns depuis l'instance
        pattern_count = len(dispatcher.patterns) if dispatcher else 0
        
        return jsonify({
            'success': True,
            'total_patterns': pattern_count,
            'patterns': dispatcher.patterns if dispatcher else [],
            'dispatcher_available': True
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500
    return {}

# üé≠ ENDPOINTS MOCK pour outils sans impl√©mentation backend
@app.route('/api/mesh/<action>', methods=['POST'])
@app.route('/api/assets/<action>', methods=['POST'])
@app.route('/api/export/<action>', methods=['POST'])
def mock_tool_endpoint(action):
    """
    Endpoint mock qui simule l'ex√©cution des outils
    Pour: mesh operations, assets, export
    """
    try:
        data = request.json or {}
        
        print(f"üîß [MOCK] Outil: {action}")
        print(f"   Params: {data}")
        
        # Simule un d√©lai de traitement
        import time
        time.sleep(0.5)
        
        return jsonify({
            'success': True,
            'tool': action,
            'message': f'‚úÖ {action} simul√© (mock)',
            'params': data,
            'note': 'Impl√©mentation backend √† venir'
        })
    
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

# ============================================
# D√âMARRAGE
# ============================================

if __name__ == '__main__':
    print("üöÄ D√©marrage de l'API Kibali-IA pour Kibalone Studio")
    print(f"üìÅ Kibali path: {KIBALI_PATH}")
    
    if init_kibali():
        print("‚úÖ Kibali-IA pr√™t")
        
        # Status des syst√®mes d'orchestration
        print("\nüéõÔ∏è  Syst√®mes d'orchestration:")
        if DISPATCHER_AVAILABLE:
            print("  ‚ö° DISPATCHER: ‚úÖ ACTIF (150+ patterns)")
        else:
            print("  ‚ö° DISPATCHER: ‚ùå Indisponible")
            
        if LANGCHAIN_AVAILABLE:
            print(f"  üîó LANGCHAIN: ‚úÖ Disponible ({len(ALL_TOOLS_DEFINITIONS)} outils)")
        else:
            print("  üîó LANGCHAIN: ‚ùå Indisponible")
        
        print("\nüåê API disponible sur: http://localhost:11000")
        print("\nEndpoints disponibles:")
        print("  GET  /api/health")
        print("  POST /api/chat")
        print("  POST /api/generate-model")
        print("  POST /api/text-to-3d")
        print("  POST /api/triposr-generate")
        print("  POST /api/analyze-prompt        ‚ö° DISPATCHER")
        print("  POST /api/generate-animation")
        print("  POST /api/camera-control")
        print("  POST /api/dispatcher/test        üß™ DEBUG")
        print("  GET  /api/dispatcher/patterns    üìö DOCS")
        
        port = int(os.environ.get('PORT', 11000))
        app.run(host='0.0.0.0', port=port, debug=False)
    else:
        print("‚ùå Impossible de d√©marrer Kibali-IA")
